-----------------------------------------------------------
    Discrete planning
-----------------------------------------------------------
- state space is finite or countably infinite (integer assignable)
- no geometric models or differential equations needed
- no uncertainty (for now)

-----------------------------------------------------------
    Problem formulation
-----------------------------------------------------------
- state x
	- takes on a value from the state space X
	- goal states X_G subset X 
- action u
	- produces new state when applied to current state
		- described by state transition function f
		f(x,u) = x'
- action space U(x)
	- set of all actions applicable to state x
	- U = union{x E X} U(x)
- directed state transition graph
	- set of vertices is X
- want compact encoding of the problem

-----------------------------------------------------------
    Search for feasibility
-----------------------------------------------------------
- graph search algorithms
- explore state transition graph incrementally
	- rather than fully specified in advance (no memory)
- important for algos to be #systematic#
	- aka complete: if finite, find a solution or declare there is none in finite time
		- accomplished by keeping track of already visited states and avoiding redundant visits
	- if infinite, find a solution in finite time if it exists, or search forever if there is none
		- accomplished by exploring every reachable vertex as search iterations -> infinite
- pretty much all the same algorithm (generalization of BFS)
	- only difference in ordering of priority queue and augmented info for each node
- unified search algo
	- incrementally construct search graph G(V,E)
		- G is subgraph of state transition graph and is the one explored so far
	1. initialize
		- E empty
		- V contains some starting nodes
			- V = {x_I} for forward search
			- V = {x_G} for backward search
			- V = {x_I, x_G} for bidirectional
	2. select vertex
		- choose n_curr in V for expansion
		- usually done by maintaining priority queue
		- x_curr is the state associated with n_curr
	3. apply an action
		- get new state x_new
		- x_new = f(x, u) for some u in U(x) for forward search
		- x = f(x_new, u) for some u in U(x_new) for backward
	4. insert directed edge into graph
		- if algo-specific tests are passed
		- if x_new not yet in V, insert into V
	5. check for solution
		- whether path exists from x_I to x_G
		- trivial if there's only a single search tree
	6. return to step 2

-----------------------------------------------------------
    Search for optimality
-----------------------------------------------------------
- uses most of the same concepts
	- new #cost functional# L
- choose to min (arbitrary selection and symmetric with max)
- first consider simpler fixed length plans
	- P_K is a K-step plan
	- P_K = (u_1, u_2, ..., u_K) K actions
	- (x_1, x_2, ..., x_K+1) derived from x_1 and f given P_K
	- let L = K + 1
	- L(P_K) = sum{k=1..K} l(x_k, u_k) + l_F(x_F)
		- l_F(x_F) = 0 if x_F in X_G else inf
		- l_F is unnecessary if L is only applied to plans that reach goal
			- but this makes notation more cumbersome to restrict the action space
			- having l_F allows extending L's domain to all plans
			- trick to convert feasibile hard constraint into optimization
	- to get feasible solution restricted to K steps, let l(x,u) := 0
	- to get min step solution <= K steps, let l(x,u) := 1
	- can let l_F(x) have != 0 values when x in X_G to represent different quality of goals
- principle of optimality: portions of an optimal plan are optimal themselves
	- if a better portion could be substituted, a better plan is found which is a contradiction
	- leads directly to #value iteration#
		- iteratively compute cost to come or cost to go
		- backward value iteration
			- uses cost to go (to x_G)
			- fixed x_G
			- let G*_k be the accumulated cost from stage k to F under execution of the optimal plan
				G*_k(x_k) = min{u_k, ... u_K}( sum{i=k..K} l(x_i, u_i) + l_F(x_F))
			- when k = F, G*_F(x_F) = l_F(x_F)
			- compute G*_k from G*_k+1
				- factor min{u_k} and l(x_k, u_k) out
				G*_k(x_k) = min{u_k}(l(x_k, u_k) + G*_k+1(x_k+1))
			- in each iteration some states will receive inf value due to unreachability
			- get G*_1 in O(K|X||U|) time
				- optimal cost to go from any initial state
		- forward value iteration
			- uses cost to come (from x_I)
			- fixed x_I
			- finds optimal plans from one initial to all goal states

-----------------------------------------------------------
    Unspecified lengths
-----------------------------------------------------------
- replace specification of K with special action u_T
	- L(P_K) = sum{k=1..K} l(x_k, u_k) + l_F(x_F) looks like the same
		- K is not pretermined so the domain of L is much larger than before
	- #termination action# u_T
		- applying u_T at x_k repeats the action forever
			- for all i >= k, u_i = u_T, x_i = x_k, l(x_i, u_T) = 0
	- plan with (u1, u2) is equivalent with (u1, u2, u_T, u_T, u_T)
	- allows optimization over all plans of length <= K
		- instead of fixed K

-----------------------------------------------------------
    Dijkstra
-----------------------------------------------------------
- similar to forward value iteration
- focuses on interesting (non-stationary value) nodes
	- good for some problems
	- not suitable for problems where this complicates the model such that computing it becomes intractable

-----------------------------------------------------------
    Logic Representation of Discrete Planning
-----------------------------------------------------------
- need implicit encodings of giant problems (10^100 states)
- can use logic to represent certain kinds of problems compactly
	- output is also human-friendly
	- historically popular
- difficult to generalize (especially compared to state-space)
	- continuous spaces
	- unpredictability
	- sensing uncertainty
	- multiple decision makers

-----------------------------------------------------------
    STRIPS Representation
-----------------------------------------------------------
- most common logic-based representation
- based on propositional logic
	- historically first-order logic
	- many variants
1. a finite, nonempty set I of instances
	- complete set of distinct things that exist
2. a finite, nonempty set P of predicates
	- binary-valued functions of >= 1 instances
	- application of a predicate to a specific set of instances is called a <positive literal>
	- logically negated positive literal is a <negative literal>
	- <complementary pair> refers to a positive literal and its counterpart negative
	- properties or statements about the instances
3. a finite, nonempty set O of operators
	- purpose is to change the world
	- each has preconditions
		- positive or negative literals that must hold for the operator to be applied
	- each has effects
		- positive or negative literals that hold as a result of applying the operator
4. an initial set S of positive literals
	- negative literals are implied by the absence of the corresponding positive literal from S
5. a goal set G of both positive and negative literals

ex. 
I = {Battery1, Battery2, Cap, Flashlight}
P = {On(Cap, Flashlight), In(Battery, Flashlight)}
O = {
	(PlaceCap, 
		predconditions: {not On(Cap, Flashlight)},
		effects: {On(Cap, Flashlight)}),
	(RemoveCap,
		preconditions: {On(Cap, Flashlight)},
		effects: {not On(Cap, Flashlight)}),
	(Insert(i),
		preconditions: {not On(Cap, Flashlight), not In(i, Flashlight)},
		effects: {In(i, Flashlight)})
	}
S = {On(Cap, Flashlight)}
G = {On(Cap, Flashlight), In(Battery1, Flashlight), In(Battery2, Flashlight)}

sample plan is (RemoveCap, Insert(Battery1), Insert(Battery2), PlaceCap)

-----------------------------------------------------------
    Converting to State-Space
-----------------------------------------------------------
- suppose every predicate has k arguments
- suppose any instance could appear in each argument
- then there are |P||I|^k complementary pairs
	- distinct individual logical statements
- to express state, a each complementary pair must be positive or negative
	- can encode with binary string
		- after imposing a linear ordering on instances and predicates
	- length of string is |P||I|^k
- size of state space is 2^(|P||I|^k) for all possible values of the state
- very small number of instances and predicates can lead to gigantic state spaces
	- classical search algos are intractable wrt |P| and |I|
- encode initial state x_I as a string (easy)
- encode goal set X_G
	- extend alphabet to have 'd' a don't care symbol
	- X_G is not a set of strings with 'd' in them
- convert operators to state transition equation f(x,u)


-----------------------------------------------------------
    Logic-Based Planning Methods
-----------------------------------------------------------
- exploit structure of a particular representation
	- a lot of heuristics
- searching in the space of partial plans
	- instead of searching in X
	- iteratively achieve required sub-goals while ensuring no conflicts arise
	- currently not considered as competitive as state space search methods
		- difficult to develop heuristics without referencing state
- build a planning graph
	- instead of the state transition graph, use much smaller <planning graph>
		- polynomial in size rather than exponential
	- contains partial information about reachability
	- indicates states that can possibly be reached
		- overapproximates reachable set
	- extracting a plan from the planning graph can take exponential time
	- layered graph (L1, O1, L2, O2, ..., L_k, O_k, L_k+1)
		- alternate literal and operators
		- li -> oi for all preconditions li of oi
		- oi-1 -> li for each effect li of oi-1
	- no variables allowed in operators
		- operators with variables are converted to a set of operators with all possible substitution of variables
	- build graph layer by layer
		- start with L1
			- place all positive literals in S in L1
			- place all negatives of anything not in S
		- Oi contains the set of all operators with preconditions as a subset of Li
		- expand until stabilization
			- need trivial operator for where l is the only precondition and effect
				- similar to termination action u_T to allow for variable length plans
	- mutex conditions
		- mutual exclusive operations o, o' E Oi
		1. inconsistent effects
			- effect of o is the negated literal of an effect of o'
		2. interference
			- effect of o is ngeated literal of a precondition o'
		3. competing needs
			- precondition from o and o' are mutex in Li
				- l, l' E Li mutex if
					1. negated literals (l = not l')
					2. inconsistent support
						- each pair o, o' E O_i-1 that achieves l and l' is mutex
						- unless an operator that achieves both l and l'
- planning as boolean satisfiability problem
	- Davis-Putnam procedure to solve satisfaction problems
		- DFS and backtracking
	- have to set stage limit (significant drawback of this approach)